{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "----\n",
    "### 04. Modeling\n",
    "\n",
    "**Objective:**  To perform models training and evaluation, this notebook workflow includes training baseline and advanced models, hyperparameter tuning, and out-of-fold (OOF) evaluation to compare all models, with a focus on the positive/fraud class. Challenged by the severe class imbalance within the dataset.\n",
    "\n",
    "---\n",
    "**Notebook Structure:**\n",
    "\n",
    "- 4.1 Library Imports & Data Loading: Load required packages and datasets.\n",
    "\n",
    "- 4.2 Train-Test Split: Prepare training and testing datasets.\n",
    "\n",
    "- 4.3 Baseline Model Training: Train simple baseline models.\n",
    "\n",
    "- 4.4 Advanced Model Training: Train advanced models eg CatBoost, LightGBM, and Random Forest classifiers.\n",
    "\n",
    "- 4.5 Hyperparameter Fine-Tuning: Tune parameters.\n",
    "\n",
    "- 4.6 Out-of-Fold Evaluation: Conduct OOF evaluation and rank all models based on PR AUC.\n",
    "\n",
    "---\n",
    "\n",
    "**Usage / Notes:** Many cells include `toggle flags (True/False)` to control execution.\n",
    "\n",
    "- Set `fine_tuning` = `True` to run hyperparameter tuning cells, otherwise leave False to skip long-running computations.\n",
    "\n",
    "- Set `save_trained_model` = `True` when you want to save a trained model, and switch to False to prevent overwriting.\n",
    "\n",
    "\n",
    "Run cells sequentially and control True/False toggle as required\n"
   ],
   "id": "581e9df56d8319ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "----\n",
    "### 4.1 Library Imports & Data Loading"
   ],
   "id": "cc16dca81fe3a2e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T12:49:37.510776Z",
     "start_time": "2025-11-23T12:49:37.502757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "\n",
    "from src.feature_engineering import FeatureEngineer"
   ],
   "id": "1f371afdc6ddd576",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T10:59:09.526909Z",
     "start_time": "2025-11-23T10:59:08.816158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.data_loader import load_data\n",
    "\n",
    "raw_data = load_data(\"../data/creditcard.csv\")\n",
    "\n",
    "raw_data.head()"
   ],
   "id": "9fc07e19a8684cb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### 4.2 Train-Test Split"
   ],
   "id": "d8e4f392bf50c8fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T10:59:09.849754Z",
     "start_time": "2025-11-23T10:59:09.734660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = raw_data.iloc[:, :-1]\n",
    "y = raw_data.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify= y, random_state=3479)"
   ],
   "id": "dfec28a82a350c0e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T10:59:09.867900Z",
     "start_time": "2025-11-23T10:59:09.865639Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.shape, y_train.shape, X_test.shape, y_test.shape",
   "id": "5e8585ee044c6d97",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((227845, 30), (227845,), (56962, 30), (56962,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "####  Train-Test Split Retention (to ensure consistency and reproducibility)",
   "id": "1f506a8248896abb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T10:59:09.931718Z",
     "start_time": "2025-11-23T10:59:09.895683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Saving the datasets\n",
    "dump(X_train, \"../data/X_train.joblib\")\n",
    "dump(y_train, \"../data/y_train.joblib\")\n",
    "dump(X_test, \"../data/X_test.joblib\")\n",
    "dump(y_test, \"../data/y_test.joblib\")"
   ],
   "id": "4db5e04fe27efd73",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/y_test.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "-----\n",
    "### 4.3 Baseline Logistic Regression Model"
   ],
   "id": "6a99a35f384e2023"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T10:59:15.808959Z",
     "start_time": "2025-11-23T10:59:09.945352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "categorical_features = [\"Time_segment\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"categorical\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "    ],\n",
    "    # keep all other columns (eg numeric features)\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# Final pipeline\n",
    "pipeline_lr = Pipeline([\n",
    "    (\"feature_engineer\", FeatureEngineer()),\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(class_weight=\"balanced\", random_state=3479, max_iter=5000))\n",
    "])\n",
    "\n",
    "pipeline_lr.fit(X_train, y_train)\n",
    "\n",
    "# Convert pipeline steps to a Pandas DataFrame\n",
    "pipeline_df = pd.DataFrame(\n",
    "    [(i+1, name, type(step).__name__) for i, (name, step) in enumerate(pipeline_lr.steps)],\n",
    "    columns=['Step', 'Name', 'Type']\n",
    ")\n",
    "\n",
    "pipeline_df.style.hide(axis=\"index\")\n",
    "# Display without the DataFrame index"
   ],
   "id": "d10e6c82d2b1b8b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13.7 s\n",
      "Wall time: 5.86 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22c5741c830>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_7363c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_7363c_level0_col0\" class=\"col_heading level0 col0\" >Step</th>\n",
       "      <th id=\"T_7363c_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_7363c_level0_col2\" class=\"col_heading level0 col2\" >Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_7363c_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_7363c_row0_col1\" class=\"data row0 col1\" >feature_engineer</td>\n",
       "      <td id=\"T_7363c_row0_col2\" class=\"data row0 col2\" >FeatureEngineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7363c_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_7363c_row1_col1\" class=\"data row1 col1\" >preprocessor</td>\n",
       "      <td id=\"T_7363c_row1_col2\" class=\"data row1 col2\" >ColumnTransformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7363c_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_7363c_row2_col1\" class=\"data row2 col1\" >classifier</td>\n",
       "      <td id=\"T_7363c_row2_col2\" class=\"data row2 col2\" >LogisticRegression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T10:59:15.845581Z",
     "start_time": "2025-11-23T10:59:15.841593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_trained_model = False  # toggle on/off saving\n",
    "\n",
    "if save_trained_model:\n",
    "    dump(pipeline_lr, \"../trained_models/logistic_regression_baseline.joblib\")"
   ],
   "id": "52e001d9ac565c12",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "`Considerations moving forward:`\n",
    "\n",
    "- I will apply balanced class weight\n",
    "- `I will utilize CatBoost and LightGBM which are gradient-boosted tree models powerful for tabular data, handle imbalanced classes well.`"
   ],
   "id": "4ba30a9192b975dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "----\n",
    "\n",
    "### 4.4 Advanced Model Training"
   ],
   "id": "33441d3c219fbd6a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 4.4.1 CatBoost Classifier (Gradient Boosted Tree model)\n",
    "\n",
    "CatBoost Classifier is a model based on gradient-boosted sequential decision trees (weak learners) where each tree corrects the previous errors. This model  has been selected to be the first advanced Classifier due to:\n",
    "\n",
    "- Native handling of categorical data.\n",
    "- Strength in handling minority classes through (`class_weights`, and `auto_class_weights = balanced`).\n",
    "- Requires minimum fine-tuning.\n",
    "\n"
   ],
   "id": "d767b78ababe6c21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:00:48.637894Z",
     "start_time": "2025-11-23T10:59:15.877649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# 1. Importing CatBoost model\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 2. Build the pipeline\n",
    "categorical_features = ['Time_segment']\n",
    "\n",
    "# Final pipeline\n",
    "pipeline_catboost = Pipeline([\n",
    "    (\"feature_engineer\", FeatureEngineer()),\n",
    "    (\"classifier\", CatBoostClassifier(\n",
    "        iterations=1000,\n",
    "        # Number of boosted trees CatBoost will build.\n",
    "        auto_class_weights=\"Balanced\",\n",
    "        # Automatically increases the importance of the minority class.\n",
    "        # Handles severe class imbalance without manually computing weights.\n",
    "        learning_rate=0.01,\n",
    "        depth=6,\n",
    "        # The depth of each decision tree.\n",
    "        cat_features=categorical_features,\n",
    "        eval_metric=\"PRAUC\",\n",
    "        # The metric CatBoost optimizes during training.\n",
    "        verbose=0 #silent training\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 3. Train/ fit the model\n",
    "pipeline_catboost.fit(X_train, y_train)\n",
    "\n",
    "# Convert pipeline steps to a Pandas DataFrame\n",
    "pipeline_df = pd.DataFrame(\n",
    "    [(i+1, name, type(step).__name__) for i, (name, step) in enumerate(pipeline_catboost.steps)],\n",
    "    columns=['Step', 'Name', 'Type']\n",
    ")\n",
    "\n",
    "pipeline_df.style.hide(axis=\"index\")\n",
    "# Display without the DataFrame index"
   ],
   "id": "cee5a16c9b4c4781",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7min 47s\n",
      "Wall time: 1min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22c57486ad0>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_0daef\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_0daef_level0_col0\" class=\"col_heading level0 col0\" >Step</th>\n",
       "      <th id=\"T_0daef_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_0daef_level0_col2\" class=\"col_heading level0 col2\" >Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_0daef_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_0daef_row0_col1\" class=\"data row0 col1\" >feature_engineer</td>\n",
       "      <td id=\"T_0daef_row0_col2\" class=\"data row0 col2\" >FeatureEngineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0daef_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_0daef_row1_col1\" class=\"data row1 col1\" >classifier</td>\n",
       "      <td id=\"T_0daef_row1_col2\" class=\"data row1 col2\" >CatBoostClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:00:48.678262Z",
     "start_time": "2025-11-23T11:00:48.673744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_trained_model = False  # toggle on/off saving\n",
    "\n",
    "if save_trained_model:\n",
    "    dump(pipeline_catboost, \"../trained_models/catboost_default.joblib\")"
   ],
   "id": "87cab3a2d53170da",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "-------\n",
    "#### 4.4.2 LightGBM (Gradient Boosted Tree model)\n",
    "LightGBM has similar strong traits e.g. handles severe class imbalance and categorical features. Moreover, it is fast on large datasets."
   ],
   "id": "1a1a87ce7a947c41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:00:48.682635Z",
     "start_time": "2025-11-23T11:00:48.680688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Suppress LightGBM feature name warnings globally\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"X does not have valid feature names\"\n",
    ")"
   ],
   "id": "58db99edbaa31109",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:00:54.926503Z",
     "start_time": "2025-11-23T11:00:48.699009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = ['Time_segment']\n",
    "\n",
    "# encode categorical features\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "], remainder=\"passthrough\")  # keep numeric features as they are\n",
    "\n",
    "pipeline_lightgbm = Pipeline([\n",
    "    (\"feature_engineer\", FeatureEngineer()),\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LGBMClassifier(\n",
    "        n_estimators=1000,\n",
    "        class_weight=\"balanced\", # handles class imbalance\n",
    "        learning_rate=0.01,\n",
    "        max_depth=6,\n",
    "        random_state=3479,\n",
    "        verbose=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline_lightgbm.fit(X_train, y_train)\n",
    "\n",
    "# Convert pipeline steps to a Pandas DataFrame\n",
    "pipeline_df = pd.DataFrame(\n",
    "    [(i+1, name, type(step).__name__) for i, (name, step) in enumerate(pipeline_lightgbm.steps)],\n",
    "    columns=['Step', 'Name', 'Type']\n",
    ")\n",
    "\n",
    "pipeline_df.style.hide(axis=\"index\")\n",
    "# Display without the DataFrame index"
   ],
   "id": "8311b8c03e344679",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 28.4 s\n",
      "Wall time: 6.22 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22c70e36850>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_163de\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_163de_level0_col0\" class=\"col_heading level0 col0\" >Step</th>\n",
       "      <th id=\"T_163de_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_163de_level0_col2\" class=\"col_heading level0 col2\" >Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_163de_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_163de_row0_col1\" class=\"data row0 col1\" >feature_engineer</td>\n",
       "      <td id=\"T_163de_row0_col2\" class=\"data row0 col2\" >FeatureEngineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_163de_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_163de_row1_col1\" class=\"data row1 col1\" >preprocessor</td>\n",
       "      <td id=\"T_163de_row1_col2\" class=\"data row1 col2\" >ColumnTransformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_163de_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_163de_row2_col1\" class=\"data row2 col1\" >classifier</td>\n",
       "      <td id=\"T_163de_row2_col2\" class=\"data row2 col2\" >LGBMClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:00:54.982822Z",
     "start_time": "2025-11-23T11:00:54.948352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_trained_model = False  # toggle on/off saving\n",
    "\n",
    "if save_trained_model:\n",
    "    dump(pipeline_lightgbm, \"../trained_models/lightgbm_default.joblib\")"
   ],
   "id": "d2f4edfd5e70b8de",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "-----\n",
    "#### 4.4.3 Random Forest Classifier\n",
    "\n",
    "(Aggregation-based ensemble algorithm it has better interpretability)"
   ],
   "id": "e50b91f9e9a4fbe5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:02:43.706696Z",
     "start_time": "2025-11-23T11:00:55.003635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "categorical_features = ['Time_segment']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "], remainder=\"passthrough\")\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    (\"feature_engineer\", FeatureEngineer()),\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(\n",
    "        max_depth=10,\n",
    "        min_samples_leaf=10,\n",
    "        random_state=3479,\n",
    "        n_estimators=1000,\n",
    "        class_weight=\"balanced\", # handles class imbalance\n",
    "        n_jobs=-1, # use all CPU cores\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "\n",
    "# Convert pipeline steps to a Pandas DataFrame\n",
    "pipeline_df = pd.DataFrame(\n",
    "    [(i+1, name, type(step).__name__) for i, (name, step) in enumerate(pipeline_rf.steps)],\n",
    "    columns=['Step', 'Name', 'Type']\n",
    ")\n",
    "pipeline_df.style.hide(axis=\"index\")"
   ],
   "id": "b2dc3e86f928bc14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 18min 43s\n",
      "Wall time: 1min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22c7ffb3390>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_de6e4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_de6e4_level0_col0\" class=\"col_heading level0 col0\" >Step</th>\n",
       "      <th id=\"T_de6e4_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_de6e4_level0_col2\" class=\"col_heading level0 col2\" >Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_de6e4_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_de6e4_row0_col1\" class=\"data row0 col1\" >feature_engineer</td>\n",
       "      <td id=\"T_de6e4_row0_col2\" class=\"data row0 col2\" >FeatureEngineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de6e4_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_de6e4_row1_col1\" class=\"data row1 col1\" >preprocessor</td>\n",
       "      <td id=\"T_de6e4_row1_col2\" class=\"data row1 col2\" >ColumnTransformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de6e4_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_de6e4_row2_col1\" class=\"data row2 col1\" >classifier</td>\n",
       "      <td id=\"T_de6e4_row2_col2\" class=\"data row2 col2\" >RandomForestClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:02:43.880337Z",
     "start_time": "2025-11-23T11:02:43.746205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_trained_model = False  # toggle on/off saving\n",
    "\n",
    "if save_trained_model:\n",
    "    dump(pipeline_rf, \"../trained_models/random_forest_default.joblib\")"
   ],
   "id": "f92f4ce861f257a4",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "-----\n",
    "### 4.5 Hyperparameters Fine-Tuning\n"
   ],
   "id": "ea1533b41a711bac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 4.5.1 Random Forest Classifier Tuning",
   "id": "a7c98ba3562bca77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:03:52.302673Z",
     "start_time": "2025-11-23T11:03:52.299228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "fine_tune_rf = False # toggle on/off the time-consuming tuning\n",
    "\n",
    "if fine_tune_rf:\n",
    "\n",
    "    # Set the step classifier\n",
    "    rf_classifier = RandomForestClassifier(class_weight=\"balanced\", random_state=1234) # handles class imbalance\n",
    "    pipeline_rf.set_params(classifier = rf_classifier)\n",
    "\n",
    "    # Distribution of the parameters to tune\n",
    "    rf_param_dist  = {\n",
    "        \"classifier__n_estimators\": [500, 1000, 1500, 2000],\n",
    "        \"classifier__max_depth\": [8, 10, 12],\n",
    "        \"classifier__min_samples_split\": [10, 20, 50],\n",
    "        \"classifier__min_samples_leaf\": [5, 10, 20],\n",
    "        \"classifier__max_features\": [\"sqrt\", \"log2\", 0.5],\n",
    "        # How many features the model looks at when splitting each node in a decision tree\n",
    "        # sqrt features, log2(features), or 50% of features\n",
    "    }\n",
    "\n",
    "    # Randomized Search for tuning\n",
    "    rf_search = RandomizedSearchCV(\n",
    "        estimator=pipeline_rf,\n",
    "        param_distributions=rf_param_dist,\n",
    "        n_iter=20,  # sample 20 combinations\n",
    "        scoring=\"average_precision\", # PR-AUC\n",
    "        cv=3,\n",
    "        random_state=3479,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    # Fit the search\n",
    "    rf_search.fit(X_train, y_train)\n",
    "\n",
    "    # Extract best model\n",
    "    rf_best_model = rf_search.best_estimator_"
   ],
   "id": "2928cda415201fa2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 7.39 μs\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:03:55.730624Z",
     "start_time": "2025-11-23T11:03:55.728239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_trained_model = False # toggle on/off saving after time-consuming tuning\n",
    "\n",
    "if save_trained_model:\n",
    "    dump(rf_best_model,\"../trained_models/random_forest_tuned_for_pr_auc.joblib\")"
   ],
   "id": "7d2a89d45fee82",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "-----\n",
    "#### 4.5.2 LightGBM Classifier Tuning"
   ],
   "id": "ee45c7df457e5384"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:02:44.187500700Z",
     "start_time": "2025-11-21T10:41:14.586657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "fine_tune_lightgbm = False # toggle on/off the time-consuming tuning\n",
    "\n",
    "if fine_tune_lightgbm:\n",
    "\n",
    "    # pos_ratio = #positives / #negatives in the dataset\n",
    "    pos_ratio = y_train.sum() / (len(y_train) - y_train.sum())\n",
    "\n",
    "    # Set the step classifier\n",
    "    lightgbm_classifier = LGBMClassifier(class_weight=\"balanced\", random_state=1234, verbose=-1) # handles class imbalance\n",
    "     # verbosity=-1 to silence warnings\n",
    "    pipeline_lightgbm.set_params(classifier = lightgbm_classifier, verbose=False)\n",
    "\n",
    "    # Distribution of the parameters to tune\n",
    "    lightgbm_param_dist = {\n",
    "        \"classifier__n_estimators\": [500, 1000, 1500], # number of trees\n",
    "        \"classifier__learning_rate\": [0.01, 0.03, 0.05],\n",
    "        \"classifier__num_leaves\": [31, 63],   # tree complexity: smaller to avoid overfitting rare positives\n",
    "        \"classifier__max_depth\": [6, 8, 10], # max tree depth\n",
    "        \"classifier__min_child_samples\": [5, 10, 20],   # min samples per leaf; prevents overfitting rare positives\n",
    "        \"classifier__subsample\": [0.8, 1.0],       # row sampling fraction; higher to see positives\n",
    "        \"classifier__colsample_bytree\": [0.8, 1.0],  # feature sampling fraction\n",
    "        \"classifier__reg_alpha\": [0.0, 0.1, 1.0],   # L1 regularization\n",
    "        \"classifier__reg_lambda\": [0.0, 0.1, 1.0],  # L2 regularization\n",
    "        \"classifier__scale_pos_weight\": [max(1, int(pos_ratio * factor)) for factor in [0.3, 0.5, 1.0,1.5, 2.0, 2.5]],\n",
    "        # dynamically  scales weight of the (positive/ fraud class) to counter imbalance\n",
    "        \"classifier__boosting_type\": ['gbdt', 'dart'], # boosting algorithm\n",
    "    }\n",
    "\n",
    "    # Randomized Search for tuning\n",
    "    lightgbm_search = RandomizedSearchCV(\n",
    "        estimator=pipeline_lightgbm,\n",
    "        param_distributions=lightgbm_param_dist,\n",
    "        n_iter=25,  # sample 20 combinations\n",
    "        scoring=\"average_precision\", # maximise PR-AUC\n",
    "        cv=3,\n",
    "        random_state=3479,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    # Fit the search\n",
    "    lightgbm_search.fit(X_train, y_train)\n",
    "\n",
    "    # Extract best model\n",
    "    light_gbm_best_model = lightgbm_search.best_estimator_"
   ],
   "id": "733c73fc2e4c764e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 48.9 s\n",
      "Wall time: 19min 16s\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:04:32.596567Z",
     "start_time": "2025-11-23T11:04:32.594113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_trained_model = False  # toggle on/off saving after time-consuming tuning\n",
    "\n",
    "if save_trained_model:\n",
    "    dump(light_gbm_best_model, \"../trained_models/lightgbm_tuned_for_pr_auc.joblib\")"
   ],
   "id": "87a14e9f6cb8018c",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "----\n",
    "#### 4.5.3 Catboost Tuning"
   ],
   "id": "f32fe633682c75b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:04:56.297687Z",
     "start_time": "2025-11-23T11:04:56.294264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "fine_tune_catboost = False # toggle on/off the time-consuming tuning\n",
    "\n",
    "if fine_tune_catboost:\n",
    "\n",
    "# Calculate class imbalance ratio\n",
    "    pos_ratio = y_train.sum() / max(1, (len(y_train) - y_train.sum()))\n",
    "\n",
    "# Initialize CatBoost classifier (silent to avoid logs)\n",
    "    categorical_features = ['Time_segment']\n",
    "\n",
    "    catboost_classifier = CatBoostClassifier(\n",
    "        random_state=1234,\n",
    "        verbose=False, # suppress output\n",
    "    )\n",
    "    pipeline_catboost.set_params(classifier = catboost_classifier)\n",
    "\n",
    "# Define parameter grid for RandomizedSearchCV\n",
    "    catboost_param_dist = {\n",
    "        \"classifier__iterations\": [500, 1000, 1500],   # number of trees\n",
    "        \"classifier__learning_rate\": [0.01, 0.03, 0.05],\n",
    "        \"classifier__depth\": [4, 6, 8],   # tree depth; smaller helps with rare positives\n",
    "        \"classifier__l2_leaf_reg\": [1, 3, 5],      # L2 regularization to smooth weights\n",
    "        \"classifier__border_count\": [32, 64, 128],   # number of bins for numerical features\n",
    "        \"classifier__scale_pos_weight\": [max(1, int(pos_ratio * f)) for f in [0.5, 1.0, 1.5, 2.0]],  # imbalance\n",
    "        \"classifier__bagging_temperature\": [0.0, 0.5, 1.0],   # randomness in bagging to reduce overfitting\n",
    "    }\n",
    "\n",
    "# Randomized Search setup\n",
    "    catboost_search = RandomizedSearchCV(\n",
    "        estimator=pipeline_catboost,\n",
    "        param_distributions=catboost_param_dist,\n",
    "        n_iter=20,  # try 20 combinations\n",
    "        scoring=\"average_precision\", # PR-AUC\n",
    "        cv=3,\n",
    "        random_state=3479,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "# Fit the search with the cat_features\n",
    "    catboost_search.fit(X_train, y_train, classifier__cat_features=categorical_features)\n",
    "\n",
    "    # Extract best model\n",
    "    catboost_best_model = catboost_search.best_estimator_"
   ],
   "id": "bb8e5a233920bdd9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 5.72 μs\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:04:59.773527Z",
     "start_time": "2025-11-23T11:04:59.771572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_trained_model = False  # toggle on/off saving after time-consuming tuning\n",
    "\n",
    "if save_trained_model:\n",
    "    dump(catboost_best_model, \"../trained_models/catboost_tuned_for_pr_auc.joblib\")"
   ],
   "id": "b6b86bad2292773e",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "-----\n",
    "### 4.6  Out-of-Fold Evaluation of All Models (Focused on Positive/Fraud Class)"
   ],
   "id": "5febc8c9b5b904b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:05:05.357643Z",
     "start_time": "2025-11-23T11:05:05.166479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_trained_models = True\n",
    "\n",
    "if load_trained_models:\n",
    "    logistic_regression_model = load(\"../trained_models/logistic_regression_baseline.joblib\")\n",
    "    catboost_model = load(\"../trained_models/catboost_default.joblib\")\n",
    "    lightgbm_model = load(\"../trained_models/lightgbm_default.joblib\")\n",
    "    rf_model = load(\"../trained_models/random_forest_default.joblib\")\n",
    "\n",
    "\n",
    "    lightgbm_model_tuned = load(\"../trained_models/lightgbm_tuned_for_pr_auc.joblib\")\n",
    "    catboost_model_tuned = load(\"../trained_models/catboost_tuned_for_pr_auc.joblib\")\n",
    "    rf_model_tuned = load(\"../trained_models/random_forest_tuned_for_pr_auc.joblib\")"
   ],
   "id": "e9370e1dae90f74e",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:17:31.606079Z",
     "start_time": "2025-11-23T11:05:09.387583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "run_oof_validation = False\n",
    "\n",
    "if run_oof_validation:\n",
    "    from src.model import oof_validation\n",
    "\n",
    "    oof_metrics = oof_validation({\"Logistic Regression (Baseline)\": logistic_regression_model,\n",
    "                                  \"CatBoost (Default)\": catboost_model,\n",
    "                                  \"LightGBM (Default)\": lightgbm_model,\n",
    "                                  \"Random Forest (Default)\": rf_model,\n",
    "                                  \"CatBoost (Tuned)\": catboost_model_tuned,\n",
    "                                  \"LightGBM (Tuned)\": lightgbm_model_tuned,\n",
    "                                  \"Random Forest (Tuned)\": rf_model_tuned,\n",
    "                                  }, X_train, y_train, categorical_features=['Time_segment']\n",
    "                             )"
   ],
   "id": "d2f6d15121674475",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because PRAUC is/are not implemented for GPU\n",
      "Metric PRAUC is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "Default metric period is 5 because PRAUC is/are not implemented for GPU\n",
      "Metric PRAUC is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "Default metric period is 5 because PRAUC is/are not implemented for GPU\n",
      "Metric PRAUC is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4min 45s\n",
      "Wall time: 12min 22s\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:18:01.299574Z",
     "start_time": "2025-11-23T11:18:01.296538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_results = False\n",
    "\n",
    "if save_results:\n",
    "    oof_metrics.to_csv(\"../results/tables/oof_validation_metrics_all_models.csv\", index=True)"
   ],
   "id": "a68cc4e63ba6194b",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:45:31.890579Z",
     "start_time": "2025-11-23T11:45:31.884602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_oof_val_metrics = True\n",
    "\n",
    "if load_oof_val_metrics:\n",
    "    oof_val_metrics = load_data(\"../results/tables/oof_validation_metrics_all_models.csv\")\n",
    "\n",
    "oof_val_metrics"
   ],
   "id": "99ac398115f4bda0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                            model  precision  recall  f1-score  support  \\\n",
       "0                CatBoost (Tuned)      0.871   0.787     0.827    394.0   \n",
       "1                LightGBM (Tuned)      0.865   0.746     0.801    394.0   \n",
       "2           Random Forest (Tuned)      0.867   0.764     0.812    394.0   \n",
       "3         Random Forest (Default)      0.846   0.794     0.819    394.0   \n",
       "4              CatBoost (Default)      0.832   0.805     0.818    394.0   \n",
       "5              LightGBM (Default)      0.763   0.759     0.761    394.0   \n",
       "6  Logistic Regression (Baseline)      0.056   0.865     0.105    394.0   \n",
       "\n",
       "   val pr auc  val roc auc  \n",
       "0       0.818        0.977  \n",
       "1       0.807        0.960  \n",
       "2       0.782        0.947  \n",
       "3       0.755        0.956  \n",
       "4       0.749        0.967  \n",
       "5       0.744        0.955  \n",
       "6       0.684        0.963  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>val pr auc</th>\n",
       "      <th>val roc auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost (Tuned)</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.827</td>\n",
       "      <td>394.0</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM (Tuned)</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.801</td>\n",
       "      <td>394.0</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest (Tuned)</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.812</td>\n",
       "      <td>394.0</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest (Default)</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.819</td>\n",
       "      <td>394.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost (Default)</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.818</td>\n",
       "      <td>394.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM (Default)</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.761</td>\n",
       "      <td>394.0</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression (Baseline)</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.105</td>\n",
       "      <td>394.0</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`Outcomes:`\n",
    "\n",
    "This out-of-fold (OOF) evaluation of all models `focuses exclusively on positive/fraud class metrics`, prioritizing performance on the fraud class.\n",
    "\n",
    "**Baseline** –– The baseline Logistic Regression achieved a PR-AUC of ~0.71, which is a strong starting point given the severe class imbalance. However, the model shows poor precision for the positive class (fraud), indicating many false positives. This underscores the need for more powerful models.\n",
    "\n",
    "**Production Candidates** –– The CatBoost (Tuned) model achieved the highest PR-AUC (~0.818) with strong precision and recall for the positive class. The tuned versions of LightGBM and Random Forest also achieved high PR-AUC, marginally behind CatBoost (Tuned). However, Random Forest (Tuned) outperforms LightGBM in precision, recall, and F1-score, making it a strong candidate when interpretability is also considered.\n",
    "\n",
    "Based on this assessment, CatBoost (Tuned) and Random Forest (Tuned) are the most suitable candidates for production, as they perform best for the positive class. A a more in-depth analysis, see the following notebook: 05_Results_analysis.\n"
   ],
   "id": "2e4ac042a57c19aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "-----------\n",
    "Next Step: Results analysis → Analyse models' performance and deploy the best mode for production\n",
    "\n",
    "------------"
   ],
   "id": "52e8c4f7c8ac2610"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
