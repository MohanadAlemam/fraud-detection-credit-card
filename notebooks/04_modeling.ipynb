{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "----\n",
    "### 04. Modeling\n",
    "\n",
    "#### Objective:\n",
    "The aim is to perform models  training and evaluation, this notebook workflow includes training a baseline and advanced models, hyperparameter tuning and out-of-fold (OOF) evaluation for all models with a focus on the positive/fraud class. Challenged by the severe class imbalance.\n",
    "\n",
    "#### Notebook Structure:\n",
    "\n",
    "- 4.1 Library Importing and Data Loading: Load necessary packages and the raw and engineered dataset.\n",
    "- 4.2 Train-Test Split: Prepare training and testing datasets.\n",
    "- 4.3 Baseline Model Training: Train  simple baseline models.\n",
    "- 4.4 Advanced Model Training: Train advanced models e.g CatBoost,  LightGBM and Random Forest classifiers.\n",
    "- 4.5 Hyperparameter Fine-Tuning: Tune the hyper-parameters.\n",
    "- 4.6 Out-of-Fold Evaluation: Conduct OOF evaluation and rank all models based on PR AUC.\n",
    "\n",
    "---\n",
    "\n",
    "#### Compute Environment/Machine:\n",
    "\n",
    "\n",
    "| Component | Specification |\n",
    "|----------|----------------|\n",
    "| CPU | AMD Ryzen 5 7600X (6 cores) |\n",
    "| RAM | 32 GB |\n",
    "| Models | Logistic Regression, Random Forest, LightGBM, CatBoost |\n",
    "\n",
    "----\n",
    "#### Approximate Runtimes (on the mentioned machine):\n",
    "\n",
    "| Task | Runtime |\n",
    "|------|---------|\n",
    "| Baseline / default models | < 2 minutes each |\n",
    "| Random Forest fine-tuning (50 iterations) | **~7 hours 45 minutes** |\n",
    "| LightGBM tuning (50 iterations) | ~41 minutes |\n",
    "| CatBoost tuning (50 iterations) | ~48 minutes |\n",
    "| OOF evaluation | ~12 minutes |\n",
    "\n",
    "---\n",
    "#### Usage Note:\n",
    "\n",
    "\n",
    "Many cells include `toggle flags (True/False)` to control execution. Run the notebook from top to bottom and switch the flags when needed:\n",
    "\n",
    "- Set `fine_tuning` = `False` to skip long-running computations.\n",
    "- Set `save_trained_model` = `False` to prevent overwriting the saved models.\n",
    "\n",
    "----\n"
   ],
   "id": "581e9df56d8319ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 4.1 Library Imports & Data Loading"
   ],
   "id": "cc16dca81fe3a2e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T11:52:55.629523100Z",
     "start_time": "2025-12-13T11:52:55.622714500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path().resolve().parent  # go up from notebooks/ to project root\n",
    "sys.path.insert(0, str(PROJECT_ROOT))"
   ],
   "id": "81b91deee3064a55",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T11:52:56.551508600Z",
     "start_time": "2025-12-13T11:52:55.960661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "\n",
    "from src.feature_engineering import FeatureEngineer\n"
   ],
   "id": "1f371afdc6ddd576",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Raw Data",
   "id": "bdaa462760fbdcb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T11:52:57.717329300Z",
     "start_time": "2025-12-13T11:52:56.953332700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.data_loader import load_data\n",
    "from src.feature_engineering import FeatureEngineer\n",
    "\n",
    "raw_data = load_data(\"../data/creditcard.csv\")\n",
    "\n",
    "raw_data.head()"
   ],
   "id": "9fc07e19a8684cb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T11:52:57.822344700Z",
     "start_time": "2025-12-13T11:52:57.749459400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split into features and target values\n",
    "X = raw_data.iloc[:, :-1]\n",
    "y = raw_data.iloc[:, -1]"
   ],
   "id": "fa4e31f4833f30d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Data After Feature Engineering",
   "id": "eebf14b54e2b6bf2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T11:52:58.825258600Z",
     "start_time": "2025-12-13T11:52:58.712344100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# apply feature engineer class operations on X\n",
    "engineer = FeatureEngineer()\n",
    "engineer.fit(X)\n",
    "engineered_X = engineer.transform(X)\n",
    "\n",
    "engineered_X.head()"
   ],
   "id": "1457ac80f9195080",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         V1        V3        V4        V6        V9       V10       V11  \\\n",
       "0 -1.359807  2.536347  1.378155  0.462388  0.363787  0.090794 -0.551600   \n",
       "1  1.191857  0.166480  0.448154 -0.082361 -0.255425 -0.166974  1.612727   \n",
       "2 -1.358354  1.773209  0.379780  1.800499 -1.514654  0.207643  0.624501   \n",
       "3 -0.966272  1.792993 -0.863291  1.247203 -1.387024 -0.054952 -0.226487   \n",
       "4 -1.158233  1.548718  0.403034  0.095921  0.817739  0.753074 -0.822843   \n",
       "\n",
       "        V12       V13       V14  ...  V7_scaled  V8_scaled  V20_scaled  \\\n",
       "0 -0.617801 -0.991390 -0.311169  ...   0.266815   0.786444    0.582942   \n",
       "1  1.065235  0.489095 -0.143772  ...   0.264875   0.786298    0.579530   \n",
       "2  0.066084  0.717293 -0.165946  ...   0.270177   0.788042    0.585855   \n",
       "3  0.178228  0.507757 -0.287924  ...   0.266803   0.789434    0.578050   \n",
       "4  0.538196  1.345852 -1.119670  ...   0.268968   0.782484    0.584615   \n",
       "\n",
       "   V21_scaled  V23_scaled  V27_scaled  V28_scaled  Amount_scaled  Hour_of_day  \\\n",
       "0    0.561184    0.663793    0.418976    0.312697       0.005824          0.0   \n",
       "1    0.557840    0.666938    0.416345    0.313423       0.000105          0.0   \n",
       "2    0.565477    0.678939    0.415489    0.311911       0.014739          0.0   \n",
       "3    0.559734    0.662607    0.417669    0.314371       0.004807          0.0   \n",
       "4    0.561327    0.663392    0.420561    0.317490       0.002724          0.0   \n",
       "\n",
       "    Time_segment  \n",
       "0  early_morning  \n",
       "1  early_morning  \n",
       "2  early_morning  \n",
       "3  early_morning  \n",
       "4  early_morning  \n",
       "\n",
       "[5 rows x 43 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V6</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>...</th>\n",
       "      <th>V7_scaled</th>\n",
       "      <th>V8_scaled</th>\n",
       "      <th>V20_scaled</th>\n",
       "      <th>V21_scaled</th>\n",
       "      <th>V23_scaled</th>\n",
       "      <th>V27_scaled</th>\n",
       "      <th>V28_scaled</th>\n",
       "      <th>Amount_scaled</th>\n",
       "      <th>Hour_of_day</th>\n",
       "      <th>Time_segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266815</td>\n",
       "      <td>0.786444</td>\n",
       "      <td>0.582942</td>\n",
       "      <td>0.561184</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0.418976</td>\n",
       "      <td>0.312697</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>early_morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264875</td>\n",
       "      <td>0.786298</td>\n",
       "      <td>0.579530</td>\n",
       "      <td>0.557840</td>\n",
       "      <td>0.666938</td>\n",
       "      <td>0.416345</td>\n",
       "      <td>0.313423</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>early_morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270177</td>\n",
       "      <td>0.788042</td>\n",
       "      <td>0.585855</td>\n",
       "      <td>0.565477</td>\n",
       "      <td>0.678939</td>\n",
       "      <td>0.415489</td>\n",
       "      <td>0.311911</td>\n",
       "      <td>0.014739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>early_morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266803</td>\n",
       "      <td>0.789434</td>\n",
       "      <td>0.578050</td>\n",
       "      <td>0.559734</td>\n",
       "      <td>0.662607</td>\n",
       "      <td>0.417669</td>\n",
       "      <td>0.314371</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>early_morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268968</td>\n",
       "      <td>0.782484</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.561327</td>\n",
       "      <td>0.663392</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.317490</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>early_morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### 4.2 Train-Test Split"
   ],
   "id": "d8e4f392bf50c8fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T11:52:59.705723800Z",
     "start_time": "2025-12-13T11:52:59.616690600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify= y, random_state=3479)"
   ],
   "id": "dfec28a82a350c0e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T11:53:00.512377700Z",
     "start_time": "2025-12-13T11:53:00.481398200Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.shape, y_train.shape, X_test.shape, y_test.shape",
   "id": "5e8585ee044c6d97",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((227845, 30), (227845,), (56962, 30), (56962,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "####  Train-Test Split Retention (to ensure consistency and reproducibility)",
   "id": "1f506a8248896abb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Saving the datasets\n",
    "dump(X_train, \"../data/X_train.joblib\")\n",
    "dump(y_train, \"../data/y_train.joblib\")\n",
    "dump(X_test, \"../data/X_test.joblib\")\n",
    "dump(y_test, \"../data/y_test.joblib\")"
   ],
   "id": "4db5e04fe27efd73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "-----\n",
    "### 4.3 Baseline Logistic Regression Model"
   ],
   "id": "6a99a35f384e2023"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T11:15:52.753379Z",
     "start_time": "2025-12-09T11:15:46.073654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "categorical_features = [\"Time_segment\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"categorical\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "    ],\n",
    "    # keep all other columns (eg numeric features)\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# Final pipeline\n",
    "pipeline_lr = Pipeline([\n",
    "    (\"feature_engineer\", FeatureEngineer()),\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(class_weight=\"balanced\", random_state=3479, max_iter=5000))\n",
    "])\n",
    "\n",
    "pipeline_lr.fit(X_train, y_train)\n",
    "\n",
    "# Convert pipeline steps to a Pandas DataFrame\n",
    "pipeline_df = pd.DataFrame(\n",
    "    [(i+1, name, type(step).__name__) for i, (name, step) in enumerate(pipeline_lr.steps)],\n",
    "    columns=['Step', 'Name', 'Type']\n",
    ")\n",
    "\n",
    "pipeline_df.style.hide(axis=\"index\")\n",
    "# Display without the DataFrame index"
   ],
   "id": "d10e6c82d2b1b8b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15c59e4e850>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_948c0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_948c0_level0_col0\" class=\"col_heading level0 col0\" >Step</th>\n",
       "      <th id=\"T_948c0_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_948c0_level0_col2\" class=\"col_heading level0 col2\" >Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_948c0_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_948c0_row0_col1\" class=\"data row0 col1\" >feature_engineer</td>\n",
       "      <td id=\"T_948c0_row0_col2\" class=\"data row0 col2\" >FeatureEngineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_948c0_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_948c0_row1_col1\" class=\"data row1 col1\" >preprocessor</td>\n",
       "      <td id=\"T_948c0_row1_col2\" class=\"data row1 col2\" >ColumnTransformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_948c0_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_948c0_row2_col1\" class=\"data row2 col1\" >classifier</td>\n",
       "      <td id=\"T_948c0_row2_col2\" class=\"data row2 col2\" >LogisticRegression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T22:27:13.779832Z",
     "start_time": "2025-12-08T22:27:13.776839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_trained_model = True  # toggle on/off saving\n",
    "\n",
    "if save_trained_model:\n",
    "    dump(pipeline_lr, \"../trained_models/logistic_regression_baseline.joblib\")"
   ],
   "id": "52e001d9ac565c12",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "`Considerations moving forward:`\n",
    "\n",
    "- I will apply balanced class weight\n",
    "- `I will utilize CatBoost and LightGBM which are gradient-boosted tree models powerful for tabular data, handle imbalanced classes well.`"
   ],
   "id": "4ba30a9192b975dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "----\n",
    "\n",
    "### 4.4 Advanced Model Training"
   ],
   "id": "33441d3c219fbd6a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4.4.1 CatBoost Classifier (Gradient Boosted Tree model)\n",
    "\n",
    "CatBoost Classifier is a model based on gradient-boosted sequential decision trees (weak learners) where each tree corrects the previous errors. This model  has been selected to be the first advanced Classifier due to:\n",
    "\n",
    "- Native handling of categorical data.\n",
    "- Strength in handling minority classes through (`class_weights`, and `auto_class_weights = balanced`).\n",
    "- Requires minimum fine-tuning.\n",
    "\n"
   ],
   "id": "d767b78ababe6c21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T11:17:21.714362Z",
     "start_time": "2025-12-09T11:16:00.305416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "# 1. Importing CatBoost model\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 2. Build the pipeline\n",
    "categorical_features = ['Time_segment']\n",
    "\n",
    "# Final pipeline\n",
    "pipeline_catboost = Pipeline([\n",
    "    (\"feature_engineer\", FeatureEngineer()),\n",
    "    (\"classifier\", CatBoostClassifier(\n",
    "        iterations=1000,\n",
    "        # Number of boosted trees CatBoost will build.\n",
    "        auto_class_weights=\"Balanced\",\n",
    "        # Automatically increases the importance of the minority class.\n",
    "        # Handles severe class imbalance without manually computing weights.\n",
    "        learning_rate=0.01,\n",
    "        depth=6,\n",
    "        # The depth of each decision tree.\n",
    "        cat_features=categorical_features,\n",
    "        eval_metric=\"PRAUC\",\n",
    "        random_state=3479,\n",
    "        # The metric CatBoost optimizes during training.\n",
    "        verbose=0 #silent training\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 3. Train/ fit the model\n",
    "pipeline_catboost.fit(X_train, y_train)\n",
    "\n",
    "# Convert pipeline steps to a Pandas DataFrame\n",
    "pipeline_df = pd.DataFrame(\n",
    "    [(i+1, name, type(step).__name__) for i, (name, step) in enumerate(pipeline_catboost.steps)],\n",
    "    columns=['Step', 'Name', 'Type']\n",
    ")\n",
    "\n",
    "pipeline_df.style.hide(axis=\"index\")\n",
    "# Display without the DataFrame index"
   ],
   "id": "cee5a16c9b4c4781",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15c59e4f390>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_2c617\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_2c617_level0_col0\" class=\"col_heading level0 col0\" >Step</th>\n",
       "      <th id=\"T_2c617_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_2c617_level0_col2\" class=\"col_heading level0 col2\" >Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_2c617_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_2c617_row0_col1\" class=\"data row0 col1\" >feature_engineer</td>\n",
       "      <td id=\"T_2c617_row0_col2\" class=\"data row0 col2\" >FeatureEngineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2c617_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_2c617_row1_col1\" class=\"data row1 col1\" >classifier</td>\n",
       "      <td id=\"T_2c617_row1_col2\" class=\"data row1 col2\" >CatBoostClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T09:39:01.353243Z",
     "start_time": "2025-12-09T09:39:01.348528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_trained_model = True  # toggle on/off saving\n",
    "\n",
    "if save_trained_model:\n",
    "    dump(pipeline_catboost, \"../trained_models/catboost_default.joblib\")"
   ],
   "id": "87cab3a2d53170da",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "-------\n",
    "### 4.4.2 LightGBM (Gradient Boosted Tree model)\n",
    "LightGBM has similar strong traits e.g. handles severe class imbalance and categorical features. Moreover, it is fast on large datasets."
   ],
   "id": "1a1a87ce7a947c41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T22:28:33.377581Z",
     "start_time": "2025-12-08T22:28:33.375517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Suppress LightGBM feature name warnings globally\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"X does not have valid feature names\"\n",
    ")"
   ],
   "id": "58db99edbaa31109",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T11:17:27.412250Z",
     "start_time": "2025-12-09T11:17:21.729102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = ['Time_segment']\n",
    "\n",
    "# encode categorical features\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "], remainder=\"passthrough\")  # keep numeric features as they are\n",
    "\n",
    "pipeline_lightgbm = Pipeline([\n",
    "    (\"feature_engineer\", FeatureEngineer()),\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LGBMClassifier(\n",
    "        n_estimators=1000,\n",
    "        class_weight=\"balanced\", # handles class imbalance\n",
    "        learning_rate=0.01,\n",
    "        max_depth=6,\n",
    "        random_state=3479,\n",
    "        verbose=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline_lightgbm.fit(X_train, y_train)\n",
    "\n",
    "# Convert pipeline steps to a Pandas DataFrame\n",
    "pipeline_df = pd.DataFrame(\n",
    "    [(i+1, name, type(step).__name__) for i, (name, step) in enumerate(pipeline_lightgbm.steps)],\n",
    "    columns=['Step', 'Name', 'Type']\n",
    ")\n",
    "\n",
    "pipeline_df.style.hide(axis=\"index\")\n",
    "# Display without the DataFrame index"
   ],
   "id": "8311b8c03e344679",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15c0c2e4690>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_5ba7f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_5ba7f_level0_col0\" class=\"col_heading level0 col0\" >Step</th>\n",
       "      <th id=\"T_5ba7f_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_5ba7f_level0_col2\" class=\"col_heading level0 col2\" >Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_5ba7f_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_5ba7f_row0_col1\" class=\"data row0 col1\" >feature_engineer</td>\n",
       "      <td id=\"T_5ba7f_row0_col2\" class=\"data row0 col2\" >FeatureEngineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5ba7f_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_5ba7f_row1_col1\" class=\"data row1 col1\" >preprocessor</td>\n",
       "      <td id=\"T_5ba7f_row1_col2\" class=\"data row1 col2\" >ColumnTransformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5ba7f_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_5ba7f_row2_col1\" class=\"data row2 col1\" >classifier</td>\n",
       "      <td id=\"T_5ba7f_row2_col2\" class=\"data row2 col2\" >LGBMClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T22:28:41.334447Z",
     "start_time": "2025-12-08T22:28:41.299281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_trained_model = True  # toggle on/off saving\n",
    "\n",
    "if save_trained_model:\n",
    "    dump(pipeline_lightgbm, \"../trained_models/lightgbm_default.joblib\")"
   ],
   "id": "d2f4edfd5e70b8de",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "-----\n",
    "### 4.4.3 Random Forest Classifier\n",
    "\n",
    "(Aggregation-based ensemble algorithm it has better interpretability)"
   ],
   "id": "e50b91f9e9a4fbe5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T11:19:39.906471Z",
     "start_time": "2025-12-09T11:17:46.819158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "categorical_features = ['Time_segment']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "], remainder=\"passthrough\")\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    (\"feature_engineer\", FeatureEngineer()),\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(\n",
    "        max_depth=10,\n",
    "        min_samples_leaf=10,\n",
    "        random_state=3479,\n",
    "        n_estimators=1000,\n",
    "        class_weight=\"balanced\", # handles class imbalance\n",
    "        n_jobs=-1, # use all CPU cores\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "\n",
    "# Convert pipeline steps to a Pandas DataFrame\n",
    "pipeline_df = pd.DataFrame(\n",
    "    [(i+1, name, type(step).__name__) for i, (name, step) in enumerate(pipeline_rf.steps)],\n",
    "    columns=['Step', 'Name', 'Type']\n",
    ")\n",
    "pipeline_df.style.hide(axis=\"index\")"
   ],
   "id": "b2dc3e86f928bc14",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15c59e4f250>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_bfc2f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_bfc2f_level0_col0\" class=\"col_heading level0 col0\" >Step</th>\n",
       "      <th id=\"T_bfc2f_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_bfc2f_level0_col2\" class=\"col_heading level0 col2\" >Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_bfc2f_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_bfc2f_row0_col1\" class=\"data row0 col1\" >feature_engineer</td>\n",
       "      <td id=\"T_bfc2f_row0_col2\" class=\"data row0 col2\" >FeatureEngineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bfc2f_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_bfc2f_row1_col1\" class=\"data row1 col1\" >preprocessor</td>\n",
       "      <td id=\"T_bfc2f_row1_col2\" class=\"data row1 col2\" >ColumnTransformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bfc2f_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_bfc2f_row2_col1\" class=\"data row2 col1\" >classifier</td>\n",
       "      <td id=\"T_bfc2f_row2_col2\" class=\"data row2 col2\" >RandomForestClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T22:30:27.120557Z",
     "start_time": "2025-12-08T22:30:26.872173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_trained_model = True  # toggle on/off saving\n",
    "\n",
    "if save_trained_model:\n",
    "    dump(pipeline_rf, \"../trained_models/random_forest_default.joblib\")"
   ],
   "id": "f92f4ce861f257a4",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "-----\n",
    "### 4.5 Hyperparameters Fine-Tuning\n"
   ],
   "id": "ea1533b41a711bac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.5.1 Random Forest Classifier Tuning",
   "id": "a7c98ba3562bca77"
  },
  {
   "metadata": {
    "tags": []
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "fine_tune_rf = True # toggle on/off the time-consuming tuning\n",
    "\n",
    "if fine_tune_rf:\n",
    "\n",
    "    # Set the step classifier\n",
    "    rf_classifier = RandomForestClassifier(class_weight=\"balanced\", random_state=1234) # handles class imbalance\n",
    "    pipeline_rf.set_params(classifier = rf_classifier)\n",
    "\n",
    "    # Distribution of the parameters to tune\n",
    "    rf_param_dist  = {\n",
    "        \"classifier__n_estimators\": [500, 1000, 1500, 2000],\n",
    "        \"classifier__max_depth\": [8, 10, 12],\n",
    "        \"classifier__min_samples_split\": [10, 20, 50],\n",
    "        \"classifier__min_samples_leaf\": [5, 10, 20],\n",
    "        \"classifier__max_features\": [\"sqrt\", \"log2\", 0.5],\n",
    "        # How many features the model looks at when splitting each node in a decision tree\n",
    "        # sqrt features, log2(features), or 50% of features\n",
    "        \"classifier__criterion\": [\"gini\", \"entropy\"],\n",
    "        \"classifier__bootstrap\": [True, False],\n",
    "    }\n",
    "\n",
    "    # Randomized Search for tuning\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=3479)\n",
    "\n",
    "    rf_search = RandomizedSearchCV(\n",
    "        estimator=pipeline_rf,\n",
    "        param_distributions=rf_param_dist,\n",
    "        n_iter=50,  # sample 50 combinations\n",
    "        scoring=\"average_precision\", # PR-AUC\n",
    "        cv=cv,\n",
    "        refit=True, # After finding the best hyperparameters, re-train the final model on the full training set as best_estimator_\n",
    "        random_state=3479,\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    # Fit the search\n",
    "    rf_search.fit(X_train, y_train)"
   ],
   "id": "2928cda415201fa2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-12-09T06:15:41.927163Z",
     "start_time": "2025-12-09T06:15:41.925377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract best model\n",
    "rf_best_model = rf_search.best_estimator_"
   ],
   "id": "eceb6251aafa0ca8",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-12-09T06:15:42.066124Z",
     "start_time": "2025-12-09T06:15:41.931407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_trained_model = True # toggle on/off saving after time-consuming tuning\n",
    "\n",
    "if save_trained_model:\n",
    "    dump(rf_best_model,\"../trained_models/random_forest_tuned_for_pr_auc.joblib\")"
   ],
   "id": "7d2a89d45fee82",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "-----\n",
    "### 4.5.2 LightGBM Classifier Tuning"
   ],
   "id": "ee45c7df457e5384"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "fine_tune_lightgbm = True # toggle on/off the time-consuming tuning\n",
    "\n",
    "if fine_tune_lightgbm:\n",
    "\n",
    "    # pos_ratio = #positives / #negatives in the dataset\n",
    "    pos_ratio = y_train.sum() / (len(y_train) - y_train.sum())\n",
    "\n",
    "    # Set the step classifier\n",
    "    lightgbm_classifier = LGBMClassifier(class_weight=\"balanced\", random_state=1234, verbose=-1) # handles class imbalance\n",
    "     # verbosity=-1 to silence warnings\n",
    "    pipeline_lightgbm.set_params(classifier = lightgbm_classifier, verbose=False)\n",
    "\n",
    "    # Distribution of the parameters to tune\n",
    "    lightgbm_param_dist = {\n",
    "        \"classifier__n_estimators\": [500, 1000, 1500], # number of trees\n",
    "        \"classifier__learning_rate\": [0.01, 0.03, 0.05],\n",
    "        \"classifier__num_leaves\": [31, 63],   # tree complexity: smaller to avoid overfitting rare positives\n",
    "        \"classifier__max_depth\": [6, 8, 10], # max tree depth\n",
    "        \"classifier__min_child_samples\": [5, 10, 20],   # min samples per leaf; prevents overfitting rare positives\n",
    "        \"classifier__subsample\": [0.8, 1.0],       # row sampling fraction; higher to see positives\n",
    "        \"classifier__colsample_bytree\": [0.8, 1.0],  # feature sampling fraction\n",
    "        \"classifier__reg_alpha\": [0.0, 0.1, 1.0],   # L1 regularization\n",
    "        \"classifier__reg_lambda\": [0.0, 0.1, 1.0],  # L2 regularization\n",
    "        \"classifier__scale_pos_weight\": [max(1, int(pos_ratio * factor)) for factor in [0.3, 0.5, 1.0,1.5, 2.0, 2.5]],\n",
    "        # dynamically  scales weight of the (positive/ fraud class) to counter imbalance\n",
    "        \"classifier__boosting_type\": ['gbdt', 'dart'], # boosting algorithm\n",
    "    }\n",
    "\n",
    "    # Randomized Search for tuning\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=3479)\n",
    "\n",
    "    lightgbm_search = RandomizedSearchCV(\n",
    "        estimator=pipeline_lightgbm,\n",
    "        param_distributions=lightgbm_param_dist,\n",
    "        n_iter=50,  # sample 50 combinations\n",
    "        scoring=\"average_precision\", # maximise PR-AUC\n",
    "        cv=cv,\n",
    "        refit=True, # After finding the best hyperparameters, re-train the final model on the full training set as best_estimator_\n",
    "        random_state=3479,\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    # Fit the search\n",
    "    lightgbm_search.fit(X_train, y_train)"
   ],
   "id": "733c73fc2e4c764e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:57:26.508428Z",
     "start_time": "2025-12-09T06:57:26.506668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract best model\n",
    "light_gbm_best_model = lightgbm_search.best_estimator_"
   ],
   "id": "6dd71f5d4737a70e",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:57:26.593436Z",
     "start_time": "2025-12-09T06:57:26.511728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_trained_model = True  # toggle on/off saving after time-consuming tuning\n",
    "\n",
    "if save_trained_model:\n",
    "    dump(light_gbm_best_model, \"../trained_models/lightgbm_tuned_for_pr_auc.joblib\")"
   ],
   "id": "87a14e9f6cb8018c",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "----\n",
    "### 4.5.3 Catboost Tuning"
   ],
   "id": "f32fe633682c75b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "fine_tune_catboost = True # toggle on/off the time-consuming tuning\n",
    "\n",
    "if fine_tune_catboost:\n",
    "\n",
    "# Calculate class imbalance ratio\n",
    "    pos_ratio = y_train.sum() / max(1, (len(y_train) - y_train.sum()))\n",
    "\n",
    "# Initialize CatBoost classifier (silent to avoid logs)\n",
    "    categorical_features = ['Time_segment']\n",
    "\n",
    "    catboost_classifier = CatBoostClassifier(\n",
    "        random_state=1234,\n",
    "        verbose=False, # suppress output\n",
    "    )\n",
    "    pipeline_catboost.set_params(classifier = catboost_classifier)\n",
    "\n",
    "# Define parameter grid for RandomizedSearchCV\n",
    "    catboost_param_dist = {\n",
    "        \"classifier__iterations\": [500, 1000, 1500],   # number of trees\n",
    "        \"classifier__learning_rate\": [0.01, 0.03, 0.05],\n",
    "        \"classifier__depth\": [4, 6, 8],   # tree depth; smaller helps with rare positives\n",
    "        \"classifier__l2_leaf_reg\": [1, 3, 5],      # L2 regularization to smooth weights\n",
    "        \"classifier__border_count\": [32, 64, 128],   # number of bins for numerical features\n",
    "        \"classifier__scale_pos_weight\": [max(1, int(pos_ratio * f)) for f in [0.5, 1.0, 1.5, 2.0]],  # imbalance\n",
    "        \"classifier__bagging_temperature\": [0.0, 0.5, 1.0],   # randomness in bagging to reduce overfitting\n",
    "    }\n",
    "\n",
    "# Randomized Search setup\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=3479)\n",
    "\n",
    "    catboost_search = RandomizedSearchCV(\n",
    "        estimator=pipeline_catboost,\n",
    "        param_distributions=catboost_param_dist,\n",
    "        n_iter=50,  # try 50 combinations\n",
    "        scoring=\"average_precision\", # PR-AUC\n",
    "        cv=cv,\n",
    "        refit=True, # After finding the best hyperparameters, re-train the final model on the full training set as best_estimator_\n",
    "        random_state=3479,\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "# Fit the search with the cat_features\n",
    "    catboost_search.fit(X_train, y_train, classifier__cat_features=categorical_features)"
   ],
   "id": "bb8e5a233920bdd9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T07:46:03.296405Z",
     "start_time": "2025-12-09T07:46:03.294711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract best model\n",
    "catboost_best_model = catboost_search.best_estimator_"
   ],
   "id": "7044589744e9d5e",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T07:46:03.303435Z",
     "start_time": "2025-12-09T07:46:03.299563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_trained_model = True  # toggle on/off saving after time-consuming tuning\n",
    "\n",
    "if save_trained_model:\n",
    "    dump(catboost_best_model, \"../trained_models/catboost_tuned_for_pr_auc.joblib\")"
   ],
   "id": "b6b86bad2292773e",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "-----\n",
    "### 4.6  Out-of-Fold Evaluation of All Models (Focused on Positive/Fraud Class)"
   ],
   "id": "5febc8c9b5b904b1"
  },
  {
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-12-13T11:53:07.688971600Z",
     "start_time": "2025-12-13T11:53:07.332430500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_trained_models = True\n",
    "\n",
    "if load_trained_models:\n",
    "    logistic_regression_model = load(\"../trained_models/logistic_regression_baseline.joblib\")\n",
    "    catboost_model = load(\"../trained_models/catboost_default.joblib\")\n",
    "    lightgbm_model = load(\"../trained_models/lightgbm_default.joblib\")\n",
    "    rf_model = load(\"../trained_models/random_forest_default.joblib\")\n",
    "\n",
    "    lightgbm_model_tuned = load(\"../trained_models/lightgbm_tuned_for_pr_auc.joblib\")\n",
    "    catboost_model_tuned = load(\"../trained_models/catboost_tuned_for_pr_auc.joblib\")\n",
    "    rf_model_tuned = load(\"../trained_models/random_forest_tuned_for_pr_auc.joblib\")"
   ],
   "id": "e9370e1dae90f74e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "tags": []
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "run_oof_validation = True\n",
    "\n",
    "if run_oof_validation:\n",
    "    from src.model import oof_validation\n",
    "\n",
    "    oof_metrics = oof_validation({\"Logistic Regression (Baseline)\": logistic_regression_model,\n",
    "                                  \"CatBoost (Default)\": catboost_model,\n",
    "                                  \"LightGBM (Default)\": lightgbm_model,\n",
    "                                  \"Random Forest (Default)\": rf_model,\n",
    "                                  \"CatBoost (Tuned)\": catboost_model_tuned,\n",
    "                                  \"LightGBM (Tuned)\": lightgbm_model_tuned,\n",
    "                                  \"Random Forest (Tuned)\": rf_model_tuned,\n",
    "                                  }, X_train, y_train, categorical_features=['Time_segment']\n",
    "                             )"
   ],
   "id": "d2f6d15121674475",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T12:15:08.372968Z",
     "start_time": "2025-12-13T12:15:08.353753300Z"
    }
   },
   "cell_type": "code",
   "source": "oof_metrics",
   "id": "4f27dedfbfac0b6b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                precision  recall  f1-score  support  \\\n",
       "model                                                                  \n",
       "LightGBM (Tuned)                    0.940   0.832     0.883    394.0   \n",
       "CatBoost (Tuned)                    0.960   0.802     0.874    394.0   \n",
       "LightGBM (Default)                  0.827   0.838     0.832    394.0   \n",
       "Random Forest (Tuned)               0.881   0.805     0.841    394.0   \n",
       "CatBoost (Default)                  0.798   0.853     0.825    394.0   \n",
       "Random Forest (Default)             0.835   0.810     0.822    394.0   \n",
       "Logistic Regression (Baseline)      0.053   0.893     0.100    394.0   \n",
       "\n",
       "                                oof pr auc (fraud)  \n",
       "model                                               \n",
       "LightGBM (Tuned)                             0.863  \n",
       "CatBoost (Tuned)                             0.856  \n",
       "LightGBM (Default)                           0.848  \n",
       "Random Forest (Tuned)                        0.839  \n",
       "CatBoost (Default)                           0.832  \n",
       "Random Forest (Default)                      0.803  \n",
       "Logistic Regression (Baseline)               0.756  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>oof pr auc (fraud)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM (Tuned)</th>\n",
       "      <td>0.940</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.883</td>\n",
       "      <td>394.0</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost (Tuned)</th>\n",
       "      <td>0.960</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.874</td>\n",
       "      <td>394.0</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM (Default)</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.832</td>\n",
       "      <td>394.0</td>\n",
       "      <td>0.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest (Tuned)</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.841</td>\n",
       "      <td>394.0</td>\n",
       "      <td>0.839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost (Default)</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.825</td>\n",
       "      <td>394.0</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest (Default)</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.822</td>\n",
       "      <td>394.0</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression (Baseline)</th>\n",
       "      <td>0.053</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.100</td>\n",
       "      <td>394.0</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-12-13T12:12:26.757683500Z",
     "start_time": "2025-12-13T12:12:26.744737300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_results = True\n",
    "\n",
    "if save_results:\n",
    "    oof_metrics.to_csv(\"../results/tables/oof_validation_metrics_all_models.csv\", index=True)"
   ],
   "id": "a68cc4e63ba6194b",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **Outcomes:**\n",
    "\n",
    "This out-of-fold (OOF) evaluation of all models `focuses exclusively on positive/fraud class metrics`, prioritizing performance on the fraud class.\n",
    "\n",
    "**Baseline** –– The baseline Logistic Regression achieved a PR-AUC of ~0.756, which is  a good starting point given the severe class imbalance. However, the model shows poor precision for the positive class (fraud),  indicating many false positives. This underscores the need for more powerful models.\n",
    "\n",
    "**Production Candidates** –– The LightGBM (Tuned) model achieved the highest PR-AUC (~0.863) with strong precision and recall for the positive class. The tuned versions of Catboost achieved comparable PR-AUC of 0.856, marginally behind LightGBM (Tuned).\n",
    "\n",
    "Based on this assessment, LightGBM (Tuned) model is the most suitable candidates for production, as it provided a high F1-score balancing precision and recall of the fraudulent transactions, while having the highest PR AUC. A more in-depth analysis, see the following notebook: 05_Results_analysis.\n"
   ],
   "id": "2e4ac042a57c19aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "-----------\n",
    "Next Step: Results analysis → Analyse models' performance and deploy the best mode for production\n",
    "\n",
    "------------"
   ],
   "id": "52e8c4f7c8ac2610"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
